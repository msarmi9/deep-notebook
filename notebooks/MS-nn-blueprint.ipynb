{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objective\" data-toc-modified-id=\"Objective-1\">Objective</a></span></li><li><span><a href=\"#Our-Data\" data-toc-modified-id=\"Our-Data-2\">Our Data</a></span></li><li><span><a href=\"#One-layer-NN\" data-toc-modified-id=\"One-layer-NN-3\">One-layer NN</a></span><ul class=\"toc-item\"><li><span><a href=\"#nn.functional\" data-toc-modified-id=\"nn.functional-3.1\">nn.functional</a></span></li><li><span><a href=\"#Logistic-Regression-Network\" data-toc-modified-id=\"Logistic-Regression-Network-3.2\">Logistic Regression Network</a></span></li></ul></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-4\">Train</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T06:02:29.089542Z",
     "start_time": "2020-07-02T06:02:28.669672Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T06:02:29.095106Z",
     "start_time": "2020-07-02T06:02:29.091908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 9\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "The goal of this notebook is to write a simple two-layer feedforward neural net in pure python. We'd also like a way to visualize how the weight space changes as we perform gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Data\n",
    "\n",
    "We'll use the breast cancer dataset from `sklearn`, which is a binary classification task with imbalanced classes (212 malignant tumors and 357 benign tumors). Each observed tumor has 30 attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T06:02:29.112792Z",
     "start_time": "2020-07-02T06:02:29.097216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T06:02:29.119195Z",
     "start_time": "2020-07-02T06:02:29.114627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (114, 30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-test-split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T06:02:29.123952Z",
     "start_time": "2020-07-02T06:02:29.120497Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize input\n",
    "mu, sigma = np.mean(X_train), np.std(X_train)\n",
    "X_train = (X_train - mu) / sigma\n",
    "X_val = (X_val - mu) / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-layer NN\n",
    "\n",
    "To start, we'll build a single layer classifier consisting of just a single linear transformation passed to an output sigmoid function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.functional\n",
    "\n",
    "Our version of `torch.nn.functional`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T06:02:29.131444Z",
     "start_time": "2020-07-02T06:02:29.125582Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    \"\"\"Pass an minibatch through a sigmoid layer.\"\"\"\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "def accuracy(y, y_hat):\n",
    "    \"\"\"Compute accuracy given soft binary predictions.\"\"\"\n",
    "    y_pred = y_hat > 0.5\n",
    "    return (y_pred == y).mean()\n",
    "\n",
    "def binary_cross_entropy(y, y_hat):\n",
    "    \"\"\"Return binary cross entropy given targets and predictions.\"\"\"\n",
    "    return np.where(y==1, -np.log(y_hat), -np.log(1 - y_hat)).mean()\n",
    "\n",
    "def binary_cross_entropy_grad(X, y, y_hat):\n",
    "    \"\"\"Return the gradient of weights and bias w.r.t binary cross entropy loss.\"\"\"\n",
    "    grad_w = 1 / len(y) * (y_hat - y) @ X \n",
    "    grad_b = np.mean(y_hat - y)\n",
    "    return grad_w, grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Network\n",
    "\n",
    "Let's build a simple class to model our single layer neural network, which is just ordinary logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T06:02:29.139101Z",
     "start_time": "2020-07-02T06:02:29.133924Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class OneLayerBinaryClassifier:\n",
    "    \"\"\"Container for a single layer binary classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_inp):\n",
    "        \"\"\"Initialise weights and bias.\"\"\"\n",
    "        self.linear = np.random.uniform(-0.1, 0.1, (n_inp, 1))\n",
    "        self.bias = np.zeros(1)\n",
    "        self.out = sigmoid\n",
    "            \n",
    "    def forward(self, X):\n",
    "        \"\"\"Pass training data through the network.\"\"\"\n",
    "        return self.out(X @ self.linear + self.bias).squeeze(1)\n",
    "    \n",
    "    def step(self, X, y, y_hat, lr):\n",
    "        \"\"\"Perform one step of gradient descent.\"\"\"\n",
    "        grad_w, grad_b = binary_cross_entropy_grad(X, y, y_hat)\n",
    "        self.linear -= lr * grad_w.reshape(-1, 1)\n",
    "        self.bias -= lr * grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "Now we're ready to put our model to the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T06:02:29.147511Z",
     "start_time": "2020-07-02T06:02:29.142240Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryTrainer:\n",
    "    \"\"\"Container for training a binary classifier.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, train_dl, val_dl, lr=1e-3):\n",
    "        self.model = model\n",
    "        self.train_dl = train_dl\n",
    "        self.val_dl = val_dl\n",
    "        self.lr = lr\n",
    "        \n",
    "    def train(self, n_epochs):\n",
    "        \"\"\"Perform gradient descent for a number of epochs.\"\"\"\n",
    "        for epoch in range(n_epochs):\n",
    "            X, y = self.train_dl\n",
    "            y_hat = self.model.forward(X)\n",
    "            loss = binary_cross_entropy(y, y_hat)\n",
    "            self.model.step(X, y, y_hat, self.lr)\n",
    "            \n",
    "            val_loss, val_acc = self.evaluate(self.val_dl)\n",
    "            print(f\"{epoch= :2d} | {loss= :.3f} | {val_loss= :.3f} | {val_acc= :.3f}\")\n",
    "            \n",
    "    def evaluate(self, dl):\n",
    "        \"\"\"Return loss and accuracy on validation or test set.\"\"\"\n",
    "        X, y = dl\n",
    "        y_hat = self.model.forward(X)\n",
    "        return binary_cross_entropy(y, y_hat), accuracy(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T06:02:29.151586Z",
     "start_time": "2020-07-02T06:02:29.149303Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bundle inputs and targets\n",
    "train_dl = (X_train, y_train)\n",
    "val_dl = (X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T06:02:29.155650Z",
     "start_time": "2020-07-02T06:02:29.153156Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialise model & trainer\n",
    "model = OneLayerBinaryClassifier(X_train.shape[1])\n",
    "trainer = BinaryTrainer(model, train_dl, val_dl,lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T06:02:29.163290Z",
     "start_time": "2020-07-02T06:02:29.157182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  0 | loss= 0.688 | val_loss= 0.679 | val_acc= 0.351\n",
      "epoch=  1 | loss= 0.677 | val_loss= 0.667 | val_acc= 0.351\n",
      "epoch=  2 | loss= 0.666 | val_loss= 0.656 | val_acc= 0.404\n",
      "epoch=  3 | loss= 0.655 | val_loss= 0.645 | val_acc= 0.482\n",
      "epoch=  4 | loss= 0.645 | val_loss= 0.634 | val_acc= 0.588\n",
      "epoch=  5 | loss= 0.636 | val_loss= 0.624 | val_acc= 0.719\n",
      "epoch=  6 | loss= 0.626 | val_loss= 0.614 | val_acc= 0.798\n",
      "epoch=  7 | loss= 0.617 | val_loss= 0.605 | val_acc= 0.860\n",
      "epoch=  8 | loss= 0.609 | val_loss= 0.596 | val_acc= 0.877\n",
      "epoch=  9 | loss= 0.601 | val_loss= 0.587 | val_acc= 0.877\n"
     ]
    }
   ],
   "source": [
    "trainer.train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T06:02:29.172037Z",
     "start_time": "2020-07-02T06:02:29.165881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=  0 | loss= 0.593 | val_loss= 0.578 | val_acc= 0.886\n",
      "epoch=  1 | loss= 0.585 | val_loss= 0.570 | val_acc= 0.886\n",
      "epoch=  2 | loss= 0.577 | val_loss= 0.562 | val_acc= 0.877\n",
      "epoch=  3 | loss= 0.570 | val_loss= 0.555 | val_acc= 0.886\n",
      "epoch=  4 | loss= 0.563 | val_loss= 0.548 | val_acc= 0.886\n",
      "epoch=  5 | loss= 0.557 | val_loss= 0.541 | val_acc= 0.904\n",
      "epoch=  6 | loss= 0.550 | val_loss= 0.534 | val_acc= 0.886\n",
      "epoch=  7 | loss= 0.544 | val_loss= 0.527 | val_acc= 0.895\n",
      "epoch=  8 | loss= 0.538 | val_loss= 0.521 | val_acc= 0.895\n",
      "epoch=  9 | loss= 0.532 | val_loss= 0.515 | val_acc= 0.904\n"
     ]
    }
   ],
   "source": [
    "trainer.train(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
